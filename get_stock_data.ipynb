{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad72fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\percy\\AppData\\Local\\Temp\\ipykernel_35604\\1788708486.py:12: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  4 of 4 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully. Inspecting columns...\n",
      "Warning: 'Adj Close' not found in downloaded data columns.\n",
      "Available top-level columns: Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n",
      "Falling back to using 'Close' price.\n",
      "\n",
      "Data processed and saved successfully!\n",
      "Ticker          AAPL    AMZN       GOOG       MSFT\n",
      "Date                                              \n",
      "2008-01-02  5.849120  4.8125  16.949791  25.299334\n",
      "2008-01-03  5.851821  4.7605  16.953255  25.407078\n",
      "2008-01-04  5.405123  4.4395  16.252443  24.695938\n",
      "2008-01-07  5.332774  4.4410  16.060728  24.861151\n",
      "2008-01-08  5.140944  4.3940  15.626096  24.027895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define the tickers and date range from the paper\n",
    "tickers = ['AAPL', 'MSFT', 'GOOG', 'AMZN']\n",
    "start_date = '2008-01-01'\n",
    "end_date = '2009-12-31' # yfinance includes the end date\n",
    "\n",
    "# 2. Download the data\n",
    "# This downloads all tickers at once into a multi-index DataFrame\n",
    "try:\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)\n",
    "    \n",
    "    if data.empty:\n",
    "        raise Exception(\"No data downloaded. Check tickers, date range, and internet connection.\")\n",
    "\n",
    "    print(\"Data downloaded successfully. Inspecting columns...\")\n",
    "    # print(data.columns) # Uncomment this for deep debugging\n",
    "\n",
    "    # 3. We only care about the 'Adj Close' price\n",
    "    # 'Adj Close' is better than 'Close' as it accounts \n",
    "    # for dividends and stock splits.\n",
    "    \n",
    "    # When downloading multiple tickers, yfinance returns a MultiIndex\n",
    "    # The top level is the measure ('Adj Close', 'Close', etc.)\n",
    "    # The KeyError means 'Adj Close' was not found as a top-level column.\n",
    "    \n",
    "    # Check if 'Adj Close' is in the top level of the columns\n",
    "    if 'Adj Close' not in data.columns.get_level_values(0):\n",
    "        print(\"Warning: 'Adj Close' not found in downloaded data columns.\")\n",
    "        print(\"Available top-level columns:\", data.columns.get_level_values(0).unique())\n",
    "        \n",
    "        # As a fallback, try to use 'Close'\n",
    "        if 'Close' in data.columns.get_level_values(0):\n",
    "            print(\"Falling back to using 'Close' price.\")\n",
    "            adj_close_data = data['Close']\n",
    "        else:\n",
    "            # If neither is present, we can't proceed\n",
    "            raise Exception(\"'Adj Close' and 'Close' not found. Cannot proceed.\")\n",
    "    else:\n",
    "        # This is the normal, expected path\n",
    "        adj_close_data = data['Adj Close']\n",
    "    \n",
    "    # 4. Save to a CSV to use in your project\n",
    "    adj_close_data.to_csv('stock_prices.csv')\n",
    "    \n",
    "    print(\"\\nData processed and saved successfully!\")\n",
    "    print(adj_close_data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaae4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker      AAPL      AMZN      GOOG      MSFT\n",
      "0       0.000201 -0.004718  0.000089  0.001846\n",
      "1      -0.034472 -0.030309 -0.018332 -0.012328\n",
      "2      -0.005852  0.000147 -0.005153  0.002896\n",
      "3      -0.015909 -0.004621 -0.011914 -0.014804\n",
      "4       0.020189 -0.013348  0.014548  0.012666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute log10(a_n / a_{n-1}) for all columns except the first\n",
    "import numpy as np\n",
    "\n",
    "log_returns = adj_close_data.copy()\n",
    "\n",
    "# Compute ratios and take log10; this updates only the selected columns\n",
    "log_returns = np.log10(log_returns / log_returns.shift(1))\n",
    "\n",
    "# Drop the first row which will be NaN due to the shift and reset the index\n",
    "log_returns = log_returns.dropna().reset_index(drop=True)\n",
    "\n",
    "#\"squash\" using arctan\n",
    "log_returns = np.arctan(log_returns)\n",
    "\n",
    "# Show the first few transformed rows\n",
    "print(log_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175b15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save squashed log returns\n",
    "\n",
    "log_returns.to_csv('squashed_log_returns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f6fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
