{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad72fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Temp\\ipykernel_41072\\718913476.py:12: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  4 of 4 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully. Inspecting columns...\n",
      "Warning: 'Adj Close' not found in downloaded data columns.\n",
      "Available top-level columns: Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n",
      "Falling back to using 'Close' price.\n",
      "\n",
      "Data processed and saved successfully!\n",
      "Ticker           AAPL       AMZN       GOOG       MSFT\n",
      "Date                                                  \n",
      "2018-01-02  40.381001  59.450500  52.888073  79.198349\n",
      "2018-01-03  40.373962  60.209999  53.756134  79.566902\n",
      "2018-01-04  40.561489  60.479500  53.950798  80.267212\n",
      "2018-01-05  41.023300  61.457001  54.736919  81.262375\n",
      "2018-01-08  40.870930  62.343498  54.970818  81.345314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define the tickers and date range from the paper\n",
    "tickers = ['AAPL', 'MSFT', 'GOOG', 'AMZN']\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31' # yfinance includes the end date\n",
    "\n",
    "# 2. Download the data\n",
    "# This downloads all tickers at once into a multi-index DataFrame\n",
    "try:\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)\n",
    "    \n",
    "    if data.empty:\n",
    "        raise Exception(\"No data downloaded. Check tickers, date range, and internet connection.\")\n",
    "\n",
    "    print(\"Data downloaded successfully. Inspecting columns...\")\n",
    "    # print(data.columns) # Uncomment this for deep debugging\n",
    "\n",
    "    # 3. We only care about the 'Adj Close' price\n",
    "    # 'Adj Close' is better than 'Close' as it accounts \n",
    "    # for dividends and stock splits.\n",
    "    \n",
    "    # When downloading multiple tickers, yfinance returns a MultiIndex\n",
    "    # The top level is the measure ('Adj Close', 'Close', etc.)\n",
    "    # The KeyError means 'Adj Close' was not found as a top-level column.\n",
    "    \n",
    "    # Check if 'Adj Close' is in the top level of the columns\n",
    "    if 'Adj Close' not in data.columns.get_level_values(0):\n",
    "        print(\"Warning: 'Adj Close' not found in downloaded data columns.\")\n",
    "        print(\"Available top-level columns:\", data.columns.get_level_values(0).unique())\n",
    "        \n",
    "        # As a fallback, try to use 'Close'\n",
    "        if 'Close' in data.columns.get_level_values(0):\n",
    "            print(\"Falling back to using 'Close' price.\")\n",
    "            adj_close_data = data['Close']\n",
    "        else:\n",
    "            # If neither is present, we can't proceed\n",
    "            raise Exception(\"'Adj Close' and 'Close' not found. Cannot proceed.\")\n",
    "    else:\n",
    "        # This is the normal, expected path\n",
    "        adj_close_data = data['Adj Close']\n",
    "    \n",
    "    # 4. Save to a CSV to use in your project\n",
    "    adj_close_data.to_csv('stock_prices.csv')\n",
    "    \n",
    "    print(\"\\nData processed and saved successfully!\")\n",
    "    print(adj_close_data.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaae4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker      AAPL      AMZN      GOOG      MSFT\n",
      "0      -0.000076  0.005513  0.007070  0.002016\n",
      "1       0.002013  0.001940  0.001570  0.003806\n",
      "2       0.004917  0.006963  0.006282  0.005351\n",
      "3      -0.001616  0.006220  0.001852  0.000443\n",
      "4      -0.000050  0.002026 -0.000267 -0.000295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute log10(a_n / a_{n-1}) for all columns except the first\n",
    "import numpy as np\n",
    "\n",
    "log_returns = adj_close_data.copy()\n",
    "\n",
    "# Compute ratios and take log10; this updates only the selected columns\n",
    "log_returns = np.log10(log_returns / log_returns.shift(1))\n",
    "\n",
    "# Drop the first row which will be NaN due to the shift and reset the index\n",
    "log_returns = log_returns.dropna().reset_index(drop=True)\n",
    "\n",
    "#\"squash\" using arctan\n",
    "log_returns = np.arctan(log_returns)\n",
    "\n",
    "# Show the first few transformed rows\n",
    "print(log_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175b15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save squashed log returns\n",
    "\n",
    "log_returns.to_csv('squashed_log_returns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f6fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
