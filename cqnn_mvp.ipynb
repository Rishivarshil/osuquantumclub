{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "453dd7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       AAPL      AMZN      GOOG      MSFT\n",
      "0 -0.000076  0.005513  0.007070  0.002016\n",
      "1  0.002013  0.001940  0.001570  0.003806\n",
      "2  0.004917  0.006963  0.006282  0.005351\n",
      "3 -0.001616  0.006220  0.001852  0.000443\n",
      "4 -0.000050  0.002026 -0.000267 -0.000295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load data from log-returns\n",
    "\n",
    "df_log_returns = pd.read_csv('squashed_log_returns.csv')\n",
    "\n",
    "print(df_log_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f46b86d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   context                                           features  raw_label\n",
      "0        0  [-7.570098556833607e-05, 0.002012513590532, 0....  -0.001616\n",
      "1        0  [0.002012513590532, 0.0049166646207804, -0.001...  -0.000050\n",
      "2        0  [0.0049166646207804, -0.0016160763885611, -4.9...  -0.000100\n",
      "3        0  [-0.0016160763885611, -4.977979782626501e-05, ...   0.002460\n",
      "4        0  [-4.977979782626501e-05, -9.973891197457896e-0...   0.004462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#split into windows\n",
    "WINDOW_SIZE = 4 #time windows of 4\n",
    "\n",
    "df = pd.DataFrame(columns=['context','features','raw_label'])\n",
    "    \n",
    "for context, ticker in enumerate(df_log_returns.columns):\n",
    "        \n",
    "    stock_series = df_log_return[ticker]\n",
    "        \n",
    "    # Slide a window across this one stock's time series\n",
    "    # We stop (window_size - 1) from the end\n",
    "    for i in range(len(stock_series) - WINDOW_SIZE + 1):\n",
    "            \n",
    "        # The full window (e.g., 4 log-returns)\n",
    "        window = stock_series.iloc[i : i + WINDOW_SIZE]\n",
    "            \n",
    "        # Features are the first N-1 (e.g., 3)\n",
    "        features = window[:-1].values\n",
    "            \n",
    "        # Label is the last one (e.g., the 4th)\n",
    "        label = window.iloc[-1]\n",
    "\n",
    "        df.loc[len(df)] = [context, features, label]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a93f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    context                                           features  raw_label  \\\n",
      "0         0  [-7.570098556833607e-05, 0.002012513590532, 0....  -0.001616   \n",
      "1         0  [0.002012513590532, 0.0049166646207804, -0.001...  -0.000050   \n",
      "2         0  [0.0049166646207804, -0.0016160763885611, -4.9...  -0.000100   \n",
      "3         0  [-0.0016160763885611, -4.977979782626501e-05, ...   0.002460   \n",
      "4         0  [-4.977979782626501e-05, -9.973891197457896e-0...   0.004462   \n",
      "5         0  [-9.973891197457896e-05, 0.0024599308278872, 0...  -0.002213   \n",
      "6         0  [0.0024599308278872, 0.0044615553560915, -0.00...   0.007114   \n",
      "7         0  [0.0044615553560915, -0.0022127250514393, 0.00...   0.000388   \n",
      "8         0  [-0.0022127250514393, 0.007114255558871, 0.000...  -0.001942   \n",
      "9         0  [0.007114255558871, 0.0003877178948868, -0.001...  -0.003568   \n",
      "10        0  [0.0003877178948868, -0.001942374603717, -0.00...   0.000098   \n",
      "11        0  [-0.001942374603717, -0.0035676390655656, 9.81...  -0.006973   \n",
      "12        0  [-0.0035676390655656, 9.81321574251727e-05, -0...  -0.007823   \n",
      "13        0  [9.81321574251727e-05, -0.0069732283076202, -0...   0.001014   \n",
      "14        0  [-0.0069732283076202, -0.0078225331054288, 0.0...  -0.009084   \n",
      "15        0  [-0.0078225331054288, 0.0010141954091522, -0.0...  -0.002567   \n",
      "16        0  [0.0010141954091522, -0.0090835460611317, -0.0...   0.001195   \n",
      "17        0  [-0.0090835460611317, -0.0025672026456246, 0.0...   0.000907   \n",
      "18        0  [-0.0025672026456246, 0.0011947578118953, 0.00...  -0.019263   \n",
      "19        0  [0.0011947578118953, 0.0009069114032109, -0.01...  -0.010988   \n",
      "\n",
      "    label  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "5       1  \n",
      "6       1  \n",
      "7       1  \n",
      "8       1  \n",
      "9       1  \n",
      "10      1  \n",
      "11      0  \n",
      "12      0  \n",
      "13      1  \n",
      "14      0  \n",
      "15      1  \n",
      "16      1  \n",
      "17      1  \n",
      "18      0  \n",
      "19      0  \n"
     ]
    }
   ],
   "source": [
    "# Convert labels to bins\n",
    "N_BINS = 2\n",
    "\n",
    "context_min = df.groupby('context')['raw_label'].transform('min')\n",
    "context_max = df.groupby('context')['raw_label'].transform('max')\n",
    "\n",
    "midpoint = (context_min + context_max) / 2\n",
    "\n",
    "df['label'] = (df['raw_label'] > midpoint).astype(int)\n",
    "\n",
    "print(df.head(20))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d15acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4816, 4)\n",
      "(1204, 4)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "\n",
    "TRAIN_RATIO = 0.8  # take the first 80% of df as requested\n",
    "\n",
    "# Compute split index using the row order (first 80%)\n",
    "n_rows = len(df)\n",
    "split_index = int(n_rows * TRAIN_RATIO)\n",
    "\n",
    "# First 80% (preserve original order); create df_test for remainder\n",
    "df_train = df.iloc[:split_index].reset_index(drop=True)\n",
    "df_test = df.iloc[split_index:].reset_index(drop=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4eb426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "#Build the circuit\n",
    "\n",
    "n_stocks = df_log_returns.shape[1]\n",
    "\n",
    "# 0-1: context qubits\n",
    "# 2-4: input qubits\n",
    "# 5: output qubit\n",
    "N_CONTEXT_WIRES = int(np.log2(n_stocks))  # Number of qubits needed to represent stocks\n",
    "N_INPUT_WIRES = df_train['features'].loc[0].shape[0]  # Should be 3\n",
    "N_OUTPUT_WIRES = int(np.log2(N_BINS))\n",
    "N_TOTAL_WIRES = N_CONTEXT_WIRES + N_INPUT_WIRES + N_OUTPUT_WIRES\n",
    "\n",
    "N_LAYERS = 2\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 10\n",
    "\n",
    "CONTEXT_WIRES = list(range(N_CONTEXT_WIRES))\n",
    "INPUT_WIRES = list(range(N_CONTEXT_WIRES, N_CONTEXT_WIRES + N_INPUT_WIRES))\n",
    "OUTPUT_WIRES = list(range(N_CONTEXT_WIRES + N_INPUT_WIRES, N_TOTAL_WIRES))\n",
    "COMP_WIRES = list(range(N_CONTEXT_WIRES, N_CONTEXT_WIRES + N_OUTPUT_WIRES + N_INPUT_WIRES))\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=6)\n",
    "\n",
    "#input layer\n",
    "def U_in(features):\n",
    "    \"\"\"The data encoding block (feature map).\"\"\"\n",
    "    # We use arctan to squash features, as discussed\n",
    "    for i, wire in enumerate(INPUT_WIRES):\n",
    "        qml.RY(features[i], wires=wire)\n",
    "\n",
    "# layer for both either the shared or specify ansatz (input is just trainable parameters)\n",
    "def U_ss(params):\n",
    "    \"\"\"A single (L=1) ansatz layer (Rotations + CNOTs).\"\"\"\n",
    "    # 1. Trainable Rotations\n",
    "    for i, wire in enumerate(COMP_WIRES):\n",
    "        qml.RY(params[i], wires=wire)\n",
    "    \n",
    "    # 2. Entangling \"Ring\"\n",
    "    for i in range(len(COMP_WIRES)):\n",
    "        qml.CNOT(wires=[COMP_WIRES[i], COMP_WIRES[(i + 1) % len(COMP_WIRES)]])\n",
    "\n",
    "@qml.qnode(dev, interface='torch', diff_method='parameter-shift')\n",
    "def circuit(features, params, context):\n",
    "    # Encode input features into qubits 2, 3, 4\n",
    "    U_in(features)\n",
    "\n",
    "    #Implement shared variational layers\n",
    "    for l in range(N_LAYERS):\n",
    "        U_ss(params['shared'][l])\n",
    "\n",
    "    #TODO: Implement actual control gates for specify layers (allows for superposition of contexts later)\n",
    "    for l in range(N_LAYERS):\n",
    "        U_ss(params['spec'][context][l])\n",
    "\n",
    "    # Measure output qubit (wire 5)\n",
    "    return qml.probs(wires=N_CONTEXT_WIRES + N_INPUT_WIRES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe8954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [-7.57009856e-05  2.01251359e-03  4.91666462e-03] Output expectation: [0.91785131 0.08214869]\n",
      "2: ──RY(-0.00)──RY(0.10)─╭●───────╭X──RY(0.50)─╭●───────╭X──RY(-0.10)─╭●───────╭X──RY(-0.20)─╭● ···\n",
      "3: ──RY(0.00)───RY(0.20)─╰X─╭●────│───RY(0.60)─╰X─╭●────│───RY(-0.10)─╰X─╭●────│───RY(-0.20)─╰X ···\n",
      "4: ──RY(0.00)───RY(0.30)────╰X─╭●─│───RY(0.70)────╰X─╭●─│───RY(-0.10)────╰X─╭●─│───RY(-0.20)─── ···\n",
      "5: ──RY(0.40)──────────────────╰X─╰●──RY(0.80)───────╰X─╰●──RY(-0.10)───────╰X─╰●──RY(-0.20)─── ···\n",
      "\n",
      "2: ··· ───────╭X─┤       \n",
      "3: ··· ─╭●────│──┤       \n",
      "4: ··· ─╰X─╭●─│──┤       \n",
      "5: ··· ────╰X─╰●─┤  Probs\n",
      "Features: [0.00551305 0.00193957 0.00696306] Output expectation: [0.92149507 0.07850493]\n",
      "2: ──RY(0.01)──RY(0.10)─╭●───────╭X──RY(0.50)─╭●───────╭X──RY(-0.30)─╭●───────╭X──RY(-0.40)─╭● ···\n",
      "3: ──RY(0.00)──RY(0.20)─╰X─╭●────│───RY(0.60)─╰X─╭●────│───RY(-0.30)─╰X─╭●────│───RY(-0.40)─╰X ···\n",
      "4: ──RY(0.01)──RY(0.30)────╰X─╭●─│───RY(0.70)────╰X─╭●─│───RY(-0.30)────╰X─╭●─│───RY(-0.40)─── ···\n",
      "5: ──RY(0.40)─────────────────╰X─╰●──RY(0.80)───────╰X─╰●──RY(-0.30)───────╰X─╰●──RY(-0.40)─── ···\n",
      "\n",
      "2: ··· ───────╭X─┤       \n",
      "3: ··· ─╭●────│──┤       \n",
      "4: ··· ─╰X─╭●─│──┤       \n",
      "5: ··· ────╰X─╰●─┤  Probs\n",
      "Features: [0.00707017 0.00156984 0.0062824 ] Output expectation: [0.8723368 0.1276632]\n",
      "2: ──RY(0.01)──RY(0.10)─╭●───────╭X──RY(0.50)─╭●───────╭X──RY(-0.50)─╭●───────╭X──RY(-0.60)─╭● ···\n",
      "3: ──RY(0.00)──RY(0.20)─╰X─╭●────│───RY(0.60)─╰X─╭●────│───RY(-0.50)─╰X─╭●────│───RY(-0.60)─╰X ···\n",
      "4: ──RY(0.01)──RY(0.30)────╰X─╭●─│───RY(0.70)────╰X─╭●─│───RY(-0.50)────╰X─╭●─│───RY(-0.60)─── ···\n",
      "5: ──RY(0.40)─────────────────╰X─╰●──RY(0.80)───────╰X─╰●──RY(-0.50)───────╰X─╰●──RY(-0.60)─── ···\n",
      "\n",
      "2: ··· ───────╭X─┤       \n",
      "3: ··· ─╭●────│──┤       \n",
      "4: ··· ─╰X─╭●─│──┤       \n",
      "5: ··· ────╰X─╰●─┤  Probs\n",
      "Features: [0.00201632 0.00380571 0.00535128] Output expectation: [0.76753135 0.23246865]\n",
      "2: ──RY(0.00)──RY(0.10)─╭●───────╭X──RY(0.50)─╭●───────╭X──RY(-0.70)─╭●───────╭X──RY(-0.80)─╭● ···\n",
      "3: ──RY(0.00)──RY(0.20)─╰X─╭●────│───RY(0.60)─╰X─╭●────│───RY(-0.70)─╰X─╭●────│───RY(-0.80)─╰X ···\n",
      "4: ──RY(0.01)──RY(0.30)────╰X─╭●─│───RY(0.70)────╰X─╭●─│───RY(-0.70)────╰X─╭●─│───RY(-0.80)─── ···\n",
      "5: ──RY(0.40)─────────────────╰X─╰●──RY(0.80)───────╰X─╰●──RY(-0.70)───────╰X─╰●──RY(-0.80)─── ···\n",
      "\n",
      "2: ··· ───────╭X─┤       \n",
      "3: ··· ─╭●────│──┤       \n",
      "4: ··· ─╰X─╭●─│──┤       \n",
      "5: ··· ────╰X─╰●─┤  Probs\n"
     ]
    }
   ],
   "source": [
    "#Test the circuit with dummy parameters\n",
    "for stock, stock_features in enumerate(train_features): \n",
    "\n",
    "    for features in stock_features[:1]: # only first element for testing\n",
    "        \n",
    "        params = dict()\n",
    "        params['shared'] = [[0.1, 0.2, 0.3, 0.4],[0.5, 0.6, 0.7, 0.8]]\n",
    "        params['spec'] = [\n",
    "            [[-0.1, -0.1, -0.1, -0.1], [-0.2, -0.2, -0.2, -0.2]],\n",
    "            [[-0.3, -0.3, -0.3, -0.3], [-0.4, -0.4, -0.4, -0.4]],\n",
    "            [[-0.5, -0.5, -0.5, -0.5], [-0.6, -0.6, -0.6, -0.6]],\n",
    "            [[-0.7, -0.7, -0.7, -0.7], [-0.8, -0.8, -0.8, -0.8]]]\n",
    "        # Execute the circuit\n",
    "        result = circuit(features, params, stock)\n",
    "        print(\"Features:\", features, \"Output expectation:\", result)\n",
    "\n",
    "        drawing = qml.draw(circuit)(features, params, stock)\n",
    "        print(drawing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 10\n",
    "\n",
    "def init_params():\n",
    "    \"\"\"\n",
    "    Initialize the trainable parameters using torch.nn.Parameter\n",
    "    \"\"\"\n",
    "    n_params_per_layer = len(COMP_WIRES) # 3 input + 1 output = 4\n",
    "    \n",
    "    # --- Shared Parameters ---\n",
    "    # We need L=2 layers of 4 params each\n",
    "    shared_params = torch.randn(N_LAYERS, n_params_per_layer, requires_grad=True)\n",
    "    \n",
    "    # --- Specify Parameters ---\n",
    "    # We need K=4 sets of (L=2 layers * 4 params each)\n",
    "    n_stocks = 2**N_CONTEXT_WIRES\n",
    "    spec_params = torch.randn(n_stocks, N_LAYERS, n_params_per_layer, requires_grad=True)\n",
    "    \n",
    "    # We use torch.nn.ParameterDict to keep them organized\n",
    "    return nn.ParameterDict({\n",
    "        \"shared\": nn.Parameter(shared_params),\n",
    "        \"spec\": nn.Parameter(spec_params)\n",
    "    })\n",
    "\n",
    "#Train the circuit\n",
    "params = init_params()\n",
    "\n",
    "optimizer = torch.optim.Adam(params.values(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "    \n",
    "    # --- Run Epochs ---\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # We loop through the training set one sample at a time\n",
    "    # (This is Stochastic Gradient Descent, Batch Size = 1)\n",
    "    for feature in train_features:\n",
    "        \n",
    "        # 1. Get data and convert to tensors\n",
    "        x_in = torch.tensor(row[['feat_0', 'feat_1', 'feat_2']].values.astype(float), dtype=torch.float32)\n",
    "        context_in = int(row['context']) # This is the classical int\n",
    "        y_true_bin = int(row['binned_label']) # e.g., 0 or 1\n",
    "        \n",
    "        # Create the one-hot true label vector [P(0), P(1)]\n",
    "        y_true_onehot = torch.tensor([0.0, 0.0])\n",
    "        y_true_onehot[y_true_bin] = 1.0\n",
    "        \n",
    "        # 2. FORWARD PASS: Run the circuit\n",
    "        # y_pred will be [P(0), P(Data(1)]\n",
    "        # We pass the classical 'context_in' integer\n",
    "        y_pred = qmtl_circuit(params, x_in, context_in)\n",
    "        \n",
    "        # 3. CALCULATE LOSS\n",
    "        # **CRITICAL**: KLDivLoss expects log-probabilities\n",
    "        # So we must take torch.log() of our circuit's output\n",
    "        loss = loss_fn(torch.log(y_pred), y_true_onehot)\n",
    "        \n",
    "        # 4. BACKWARD PASS: Calculate gradients\n",
    "        # This is the \"magic\"\n",
    "        # PyTorch and PennyLane work together to run the\n",
    "        # parameter-shift rule for ALL parameters.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. UPDATE PARAMETERS\n",
    "        # The optimizer updates our 'params' dictionary\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 6. CLEAR GRADIENTS\n",
    "        # We must clear gradients for the next sample\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(df_train)\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS} - Avg. Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"--- Training Complete ---\")\n",
    "    print(\"Final Parameters (Shared):\")\n",
    "    print(params['shared'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
